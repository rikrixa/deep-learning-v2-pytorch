{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.',\n",
       " \"You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install -q tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re, sys, math, spacy, transformers, os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from tensorboardX import SummaryWriter\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "my_region = boto3.session.Session().region_name\n",
    "bucket = \"s3://alkymi-sftp/coleman/\"\n",
    "data_dir = \"https://alkymi-sftp.s3.amazonaws.com/coleman/Training_Data_ML_FINAL_Alkymi.xlsx\"\n",
    "instance_type = \"ml.p2.8xlarge\"\n",
    "role = get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smdistributed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3ab8264e7f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msmdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'smdistributed'"
     ]
    }
   ],
   "source": [
    "import smdistributed.dataparallel.torch.parallel.distributed as dist\n",
    "dist.init_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Training_Data_ML_FINAL_Alkymi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2646bdf56d9c4649adb112c2af340d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Employee Background Checks</td>\n",
       "      <td>We are looking to schedule calls with experts ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>Employment Screening Resources; Employment Scr...</td>\n",
       "      <td>Application Software; Research &amp; Consulting Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Formers</td>\n",
       "      <td>One of our clients, an Analyst at a Private Eq...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Former</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Customers</td>\n",
       "      <td>One of our clients, an Analyst at a Private Eq...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Retail Media Networks &amp; Money Services</td>\n",
       "      <td>Subject: Expert interview request from BCGReq...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grocery Stores;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Media</td>\n",
       "      <td>Experts who have built or directly worked with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walmart Inc.; Kmart Corporation; CVS Health Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Competitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProjectId                             ProjectName  \\\n",
       "0  10049566.0             Employee Background Checks    \n",
       "1  10049566.0                                 Formers   \n",
       "2  10049566.0                               Customers   \n",
       "3  10047873.0  Retail Media Networks & Money Services   \n",
       "4  10047873.0                                   Media   \n",
       "\n",
       "                                  ProjectDescription               CallDate  \\\n",
       "0  We are looking to schedule calls with experts ...  11/16/2020 3:00:00 PM   \n",
       "1  One of our clients, an Analyst at a Private Eq...                    NaN   \n",
       "2  One of our clients, an Analyst at a Private Eq...                    NaN   \n",
       "3   Subject: Expert interview request from BCGReq...  11/16/2020 3:00:00 PM   \n",
       "4  Experts who have built or directly worked with...                    NaN   \n",
       "\n",
       "                                           Companies  \\\n",
       "0  Employment Screening Resources; Employment Scr...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Walmart Inc.; Kmart Corporation; CVS Health Co...   \n",
       "\n",
       "                                          Industries Countries  \\\n",
       "0  Application Software; Research & Consulting Se...       NaN   \n",
       "1                                                NaN       NaN   \n",
       "2                                                NaN       NaN   \n",
       "3                                   Grocery Stores;        NaN   \n",
       "4                                                NaN       NaN   \n",
       "\n",
       "  RequestedConsultations    Deadline  Column1   _1  \n",
       "0                      2         NaN      NaN  NaN  \n",
       "1                    NaN      Former      NaN  NaN  \n",
       "2                    NaN    Customer      NaN  NaN  \n",
       "3                     10         NaN      NaN  NaN  \n",
       "4                    NaN  Competitor      NaN  NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProjectId'].fillna(method='ffill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['ProjectId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Employee Background Checks</td>\n",
       "      <td>We are looking to schedule calls with experts ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[Employment Screening Resources,  Employment S...</td>\n",
       "      <td>Application Software; Research &amp; Consulting Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Retail Media Networks &amp; Money Services</td>\n",
       "      <td>Subject: Expert interview request from BCGReq...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery Stores;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10046431.0</td>\n",
       "      <td>Interventional Radiology</td>\n",
       "      <td>Dear Nicole, Hope you’re well. We are currentl...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Medical Equipment;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11/30/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10048463.0</td>\n",
       "      <td>COVID-19 Testing</td>\n",
       "      <td>Hey Sean – This one is moving forward!  60 Min...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Airports and Airport Terminal Services; Colleg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>11/25/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10048901.0</td>\n",
       "      <td>Virtual Hybrid Events</td>\n",
       "      <td>Coleman Research,McKinsey &amp; Company has a new ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Event Planning Industry Software;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectId                             ProjectName  \\\n",
       "0   10049566.0             Employee Background Checks    \n",
       "3   10047873.0  Retail Media Networks & Money Services   \n",
       "7   10046431.0               Interventional Radiology    \n",
       "12  10048463.0                        COVID-19 Testing   \n",
       "14  10048901.0                   Virtual Hybrid Events   \n",
       "\n",
       "                                   ProjectDescription               CallDate  \\\n",
       "0   We are looking to schedule calls with experts ...  11/16/2020 3:00:00 PM   \n",
       "3    Subject: Expert interview request from BCGReq...  11/16/2020 3:00:00 PM   \n",
       "7   Dear Nicole, Hope you’re well. We are currentl...  11/16/2020 3:00:00 PM   \n",
       "12  Hey Sean – This one is moving forward!  60 Min...  11/16/2020 3:00:00 PM   \n",
       "14  Coleman Research,McKinsey & Company has a new ...  11/16/2020 3:00:00 PM   \n",
       "\n",
       "                                            Companies  \\\n",
       "0   [Employment Screening Resources,  Employment S...   \n",
       "3                                                  []   \n",
       "7                                                  []   \n",
       "12                                                 []   \n",
       "14                                                 []   \n",
       "\n",
       "                                           Industries Countries  \\\n",
       "0   Application Software; Research & Consulting Se...       NaN   \n",
       "3                                    Grocery Stores;        NaN   \n",
       "7                                 Medical Equipment;        NaN   \n",
       "12  Airports and Airport Terminal Services; Colleg...       NaN   \n",
       "14                 Event Planning Industry Software;        NaN   \n",
       "\n",
       "   RequestedConsultations                Deadline  Column1   _1  \n",
       "0                       2                     NaN      NaN  NaN  \n",
       "3                      10                     NaN      NaN  NaN  \n",
       "7                      40  11/30/2020 12:00:00 PM      NaN  NaN  \n",
       "12                      8  11/25/2020 12:00:00 PM      NaN  NaN  \n",
       "14                      5                     NaN      NaN  NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Companies']=df['Companies'].fillna(\"\")\n",
    "df['Companies']=df['Companies'].apply(lambda y:y.split(';')[:-1] if y!=None else y)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def put_periods(token):\n",
    "    \n",
    "    d,pos=defaultdict(),0\n",
    "    for i in range(len(token)):\n",
    "        end=len(token[i])\n",
    "        for j in range(len(token[i])):\n",
    "            \n",
    "            if j!=0 and j!=len(token[i])-1 and (token[i][j]==')' or token[i][j]==']' or token[i][j]=='}'):\n",
    "                if end==len(token[i]):\n",
    "                    end=j\n",
    "                d[pos+1]='.'\n",
    "                d[pos+2]=token[i][j+1:]\n",
    "                break\n",
    "        pos+=1\n",
    "        token[i]=token[i][:j+1]\n",
    "    for k,v in d.items():\n",
    "        token.insert(k,v)\n",
    "    return token\n",
    "\n",
    "\n",
    "def convert_to_words(x):\n",
    "    #nlp.disable_pipes('ner', 'tagger', 'parser')\n",
    "    doc=nlp(x)\n",
    "    #tokens_pd = [token.text for token in doc]\n",
    "    tokens_pd = put_periods([token.text for token in doc])\n",
    "    return tokens_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tags(xw,y):\n",
    "    if y==None:\n",
    "        tags=['O' for i in xw]\n",
    "        return tags\n",
    "    doc_y=[nlp(i) for i in y]\n",
    "    cs=[[token.text for token in i if token.text.isalnum()] for i in doc_y]\n",
    "    #print(cs)\n",
    "    cf = [i[0] for i in cs if len(i)>0]\n",
    "    cfs=[i[0]+i[1] for i in cs if len(i)>1]\n",
    "    \n",
    "    tags,f=[],0\n",
    "    for i in xw:\n",
    "        if i in cf or i in cfs:\n",
    "            tags.append('B-COM')\n",
    "            f=1\n",
    "            if i in cf:\n",
    "                ind=[j for j,y in enumerate(cf)]\n",
    "            else:\n",
    "                ind=[j for j,y in enumerate(cfs)]\n",
    "        elif f: \n",
    "            found=0\n",
    "            for k in ind:\n",
    "                if i in cs[k]:\n",
    "                    found=1\n",
    "                    tags.append('I-COM')\n",
    "                    break\n",
    "            if not found:\n",
    "                tags.append('O')\n",
    "                f=0\n",
    "        else:\n",
    "            tags.append('O')\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ProjectId, ProjectName, ProjectDescription, CallDate, Companies, Industries, Countries, RequestedConsultations, Deadline, Column1, _1]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df[\"ProjectDescription\"].isna().sum()\n",
    "print(count)\n",
    "#df[df['ProjectDescription'].isnull()]\n",
    "df = df[df['ProjectDescription'].notna()]\n",
    "df[df['ProjectDescription'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Employee Background Checks</td>\n",
       "      <td>We are looking to schedule calls with experts ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[Employment Screening Resources,  Employment S...</td>\n",
       "      <td>Application Software; Research &amp; Consulting Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[We, are, looking, to, schedule, calls, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Retail Media Networks &amp; Money Services</td>\n",
       "      <td>Subject: Expert interview request from BCGReq...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery Stores;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ , Subject, :, Expert, interview, request, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10046431.0</td>\n",
       "      <td>Interventional Radiology</td>\n",
       "      <td>Dear Nicole, Hope you’re well. We are currentl...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Medical Equipment;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11/30/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Dear, Nicole, ,, Hope, you, ’re, well, ., We,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10048463.0</td>\n",
       "      <td>COVID-19 Testing</td>\n",
       "      <td>Hey Sean – This one is moving forward!  60 Min...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Airports and Airport Terminal Services; Colleg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>11/25/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Hey, Sean, –, This, one, is, moving, forward,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10048901.0</td>\n",
       "      <td>Virtual Hybrid Events</td>\n",
       "      <td>Coleman Research,McKinsey &amp; Company has a new ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Event Planning Industry Software;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Coleman, Research, ,, McKinsey, &amp;, Company, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectId                             ProjectName  \\\n",
       "0   10049566.0             Employee Background Checks    \n",
       "3   10047873.0  Retail Media Networks & Money Services   \n",
       "7   10046431.0               Interventional Radiology    \n",
       "12  10048463.0                        COVID-19 Testing   \n",
       "14  10048901.0                   Virtual Hybrid Events   \n",
       "\n",
       "                                   ProjectDescription               CallDate  \\\n",
       "0   We are looking to schedule calls with experts ...  11/16/2020 3:00:00 PM   \n",
       "3    Subject: Expert interview request from BCGReq...  11/16/2020 3:00:00 PM   \n",
       "7   Dear Nicole, Hope you’re well. We are currentl...  11/16/2020 3:00:00 PM   \n",
       "12  Hey Sean – This one is moving forward!  60 Min...  11/16/2020 3:00:00 PM   \n",
       "14  Coleman Research,McKinsey & Company has a new ...  11/16/2020 3:00:00 PM   \n",
       "\n",
       "                                            Companies  \\\n",
       "0   [Employment Screening Resources,  Employment S...   \n",
       "3                                                  []   \n",
       "7                                                  []   \n",
       "12                                                 []   \n",
       "14                                                 []   \n",
       "\n",
       "                                           Industries Countries  \\\n",
       "0   Application Software; Research & Consulting Se...       NaN   \n",
       "3                                    Grocery Stores;        NaN   \n",
       "7                                 Medical Equipment;        NaN   \n",
       "12  Airports and Airport Terminal Services; Colleg...       NaN   \n",
       "14                 Event Planning Industry Software;        NaN   \n",
       "\n",
       "   RequestedConsultations                Deadline  Column1   _1  \\\n",
       "0                       2                     NaN      NaN  NaN   \n",
       "3                      10                     NaN      NaN  NaN   \n",
       "7                      40  11/30/2020 12:00:00 PM      NaN  NaN   \n",
       "12                      8  11/25/2020 12:00:00 PM      NaN  NaN   \n",
       "14                      5                     NaN      NaN  NaN   \n",
       "\n",
       "                                                words  \n",
       "0   [We, are, looking, to, schedule, calls, with, ...  \n",
       "3   [ , Subject, :, Expert, interview, request, fr...  \n",
       "7   [Dear, Nicole, ,, Hope, you, ’re, well, ., We,...  \n",
       "12  [Hey, Sean, –, This, one, is, moving, forward,...  \n",
       "14  [Coleman, Research, ,, McKinsey, &, Company, h...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words']=df['ProjectDescription'].apply(lambda x: convert_to_words(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'Subject', ':', 'Expert', 'interview', 'request', 'from', 'BCGRequestor', 'Name', ':', 'Marlin', 'BottexRequestor', 'Email', ':', 'Bottex', '.', 'Marlin@bcg.comRequestor', 'Phone', ':', 'Requestor', 'Office', ':', 'Los', 'AngelesRequestor', 'Time', 'Zone', ':', 'US', '/', 'PacificShort', 'Title', '/', 'Subject', ':', 'Retail', 'Media', 'Networks', '&', 'Money', 'ServicesProject', 'Description', ':', 'I', \"'m\", 'looking', 'to', 'talk', 'to', 'experts', 'who', 'have', 'built', 'or', 'directly', 'worked', 'within', 'either', 'of', 'these', 'two', 'types', 'for', 'businesses', 'for', 'a', 'mainly', 'brick', 'and', 'mortar', 'retailer', ':', 'Retail', 'Media', 'Networks', '&', 'Money', 'Services', '.', 'These', 'are', 'both', 'alternate', 'sources', 'of', 'revenue', 'for', 'retailors', 'that', 'have', 'them', '.', 'In', 'Retail', 'Media', 'Networks', '(', 'retailer', 'sells', 'marketing', '&', 'advertising', ',', 'e.g.', ',', 'sells', 'signage', 'in', 'stores', 'or', 'space', 'on', 'an', 'email', 'or', 'owned', 'web', 'page', 'or', 'physical', 'billboard', 'for', 'revenue)', '.', '-', 'companies', 'they', 'could', \"'ve\", 'worked', 'for', 'include', 'Target', ',', 'Walmart', ',', 'Lowes', ',', 'CVS', 'In', 'Money', 'services', '(', 'cash', 'a', 'check', ',', 'get', 'cash', 'back', 'off', 'a', 'debit', 'card', ',', 'buy', 'a', 'money', 'order', ',', 'pay', 'bills', 'and', 'send', 'or', 'pick', 'up', 'money', ')', '-', 'companies', 'include', 'Walmart', ',', 'Kmart', ',', 'Albertsons', ',', 'Wegmans', '.', '\\ufeffIndustry', ',', 'Publix)', 'your', 'end', '-', 'client', 'operates', 'in', ':', 'Convenience', '&', 'Grocery', 'RetailAnticipated', '#', 'of', 'Interviews', ':', '10Date', 'to', 'Start', 'Interview', ':', '2020', '-', '10', '-', '20Date', 'to', 'End', 'Interview', ':', '2020', '-', '10', '-', '30BCG', 'Case', 'Code', ':', ' ']\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "yt=df.loc[3,'tags']\n",
    "mxm = df.loc[3,'words']\n",
    "print(mxm)\n",
    "print(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Employee Background Checks</td>\n",
       "      <td>We are looking to schedule calls with experts ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[Employment Screening Resources,  Employment S...</td>\n",
       "      <td>Application Software; Research &amp; Consulting Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[We, are, looking, to, schedule, calls, with, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Retail Media Networks &amp; Money Services</td>\n",
       "      <td>Subject: Expert interview request from BCGReq...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery Stores;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ , Subject, :, Expert, interview, request, fr...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10046431.0</td>\n",
       "      <td>Interventional Radiology</td>\n",
       "      <td>Dear Nicole, Hope you’re well. We are currentl...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Medical Equipment;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11/30/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Dear, Nicole, ,, Hope, you, ’re, well, ., We,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10048463.0</td>\n",
       "      <td>COVID-19 Testing</td>\n",
       "      <td>Hey Sean – This one is moving forward!  60 Min...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Airports and Airport Terminal Services; Colleg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>11/25/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Hey, Sean, –, This, one, is, moving, forward,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10048901.0</td>\n",
       "      <td>Virtual Hybrid Events</td>\n",
       "      <td>Coleman Research,McKinsey &amp; Company has a new ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Event Planning Industry Software;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Coleman, Research, ,, McKinsey, &amp;, Company, h...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectId                             ProjectName  \\\n",
       "0   10049566.0             Employee Background Checks    \n",
       "3   10047873.0  Retail Media Networks & Money Services   \n",
       "7   10046431.0               Interventional Radiology    \n",
       "12  10048463.0                        COVID-19 Testing   \n",
       "14  10048901.0                   Virtual Hybrid Events   \n",
       "\n",
       "                                   ProjectDescription               CallDate  \\\n",
       "0   We are looking to schedule calls with experts ...  11/16/2020 3:00:00 PM   \n",
       "3    Subject: Expert interview request from BCGReq...  11/16/2020 3:00:00 PM   \n",
       "7   Dear Nicole, Hope you’re well. We are currentl...  11/16/2020 3:00:00 PM   \n",
       "12  Hey Sean – This one is moving forward!  60 Min...  11/16/2020 3:00:00 PM   \n",
       "14  Coleman Research,McKinsey & Company has a new ...  11/16/2020 3:00:00 PM   \n",
       "\n",
       "                                            Companies  \\\n",
       "0   [Employment Screening Resources,  Employment S...   \n",
       "3                                                  []   \n",
       "7                                                  []   \n",
       "12                                                 []   \n",
       "14                                                 []   \n",
       "\n",
       "                                           Industries Countries  \\\n",
       "0   Application Software; Research & Consulting Se...       NaN   \n",
       "3                                    Grocery Stores;        NaN   \n",
       "7                                 Medical Equipment;        NaN   \n",
       "12  Airports and Airport Terminal Services; Colleg...       NaN   \n",
       "14                 Event Planning Industry Software;        NaN   \n",
       "\n",
       "   RequestedConsultations                Deadline  Column1   _1  \\\n",
       "0                       2                     NaN      NaN  NaN   \n",
       "3                      10                     NaN      NaN  NaN   \n",
       "7                      40  11/30/2020 12:00:00 PM      NaN  NaN   \n",
       "12                      8  11/25/2020 12:00:00 PM      NaN  NaN   \n",
       "14                      5                     NaN      NaN  NaN   \n",
       "\n",
       "                                                words  \\\n",
       "0   [We, are, looking, to, schedule, calls, with, ...   \n",
       "3   [ , Subject, :, Expert, interview, request, fr...   \n",
       "7   [Dear, Nicole, ,, Hope, you, ’re, well, ., We,...   \n",
       "12  [Hey, Sean, –, This, one, is, moving, forward,...   \n",
       "14  [Coleman, Research, ,, McKinsey, &, Company, h...   \n",
       "\n",
       "                                                 tags  \n",
       "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "12  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "14  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags']=df[['words','Companies']].apply(lambda x: make_tags(*x), axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>ProjectName</th>\n",
       "      <th>ProjectDescription</th>\n",
       "      <th>CallDate</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Countries</th>\n",
       "      <th>RequestedConsultations</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>_1</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10049566.0</td>\n",
       "      <td>Employee Background Checks</td>\n",
       "      <td>We are looking to schedule calls with experts ...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[Employment Screening Resources,  Employment S...</td>\n",
       "      <td>Application Software; Research &amp; Consulting Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[We, are, looking, to, schedule, calls, with, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047873.0</td>\n",
       "      <td>Retail Media Networks &amp; Money Services</td>\n",
       "      <td>Subject : Expert interview request from BCGR...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grocery Stores;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ , Subject, :, Expert, interview, request, fr...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10046431.0</td>\n",
       "      <td>Interventional Radiology</td>\n",
       "      <td>Dear Nicole , Hope you ’re well . We are curre...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Medical Equipment;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11/30/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Dear, Nicole, ,, Hope, you, ’re, well, ., We,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10048463.0</td>\n",
       "      <td>COVID-19 Testing</td>\n",
       "      <td>Hey Sean – This one is moving forward !   60 M...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Airports and Airport Terminal Services; Colleg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>11/25/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Hey, Sean, –, This, one, is, moving, forward,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10048901.0</td>\n",
       "      <td>Virtual Hybrid Events</td>\n",
       "      <td>Coleman Research , McKinsey &amp; Company has a ne...</td>\n",
       "      <td>11/16/2020 3:00:00 PM</td>\n",
       "      <td>[]</td>\n",
       "      <td>Event Planning Industry Software;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Coleman, Research, ,, McKinsey, &amp;, Company, h...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProjectId                             ProjectName  \\\n",
       "0   10049566.0             Employee Background Checks    \n",
       "3   10047873.0  Retail Media Networks & Money Services   \n",
       "7   10046431.0               Interventional Radiology    \n",
       "12  10048463.0                        COVID-19 Testing   \n",
       "14  10048901.0                   Virtual Hybrid Events   \n",
       "\n",
       "                                   ProjectDescription               CallDate  \\\n",
       "0   We are looking to schedule calls with experts ...  11/16/2020 3:00:00 PM   \n",
       "3     Subject : Expert interview request from BCGR...  11/16/2020 3:00:00 PM   \n",
       "7   Dear Nicole , Hope you ’re well . We are curre...  11/16/2020 3:00:00 PM   \n",
       "12  Hey Sean – This one is moving forward !   60 M...  11/16/2020 3:00:00 PM   \n",
       "14  Coleman Research , McKinsey & Company has a ne...  11/16/2020 3:00:00 PM   \n",
       "\n",
       "                                            Companies  \\\n",
       "0   [Employment Screening Resources,  Employment S...   \n",
       "3                                                  []   \n",
       "7                                                  []   \n",
       "12                                                 []   \n",
       "14                                                 []   \n",
       "\n",
       "                                           Industries Countries  \\\n",
       "0   Application Software; Research & Consulting Se...       NaN   \n",
       "3                                    Grocery Stores;        NaN   \n",
       "7                                 Medical Equipment;        NaN   \n",
       "12  Airports and Airport Terminal Services; Colleg...       NaN   \n",
       "14                 Event Planning Industry Software;        NaN   \n",
       "\n",
       "   RequestedConsultations                Deadline  Column1   _1  \\\n",
       "0                       2                     NaN      NaN  NaN   \n",
       "3                      10                     NaN      NaN  NaN   \n",
       "7                      40  11/30/2020 12:00:00 PM      NaN  NaN   \n",
       "12                      8  11/25/2020 12:00:00 PM      NaN  NaN   \n",
       "14                      5                     NaN      NaN  NaN   \n",
       "\n",
       "                                                words  \\\n",
       "0   [We, are, looking, to, schedule, calls, with, ...   \n",
       "3   [ , Subject, :, Expert, interview, request, fr...   \n",
       "7   [Dear, Nicole, ,, Hope, you, ’re, well, ., We,...   \n",
       "12  [Hey, Sean, –, This, one, is, moving, forward,...   \n",
       "14  [Coleman, Research, ,, McKinsey, &, Company, h...   \n",
       "\n",
       "                                                 tags  \n",
       "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "12  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "14  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProjectDescription']=df['words'].apply(lambda xw: ' '.join(xw))\n",
    "#df['tags']=df['tags'].apply(lambda xw:' '.join(xw))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21193 5299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "texts=df['ProjectDescription'].to_list()\n",
    "tags=df['tags'].to_list()\n",
    "words=df['words'].to_list()\n",
    "train_texts,val_texts,train_tags,val_tags,train_words,val_words = train_test_split(texts,tags,words,test_size=.2)\n",
    "train_encodings =tokenizer(train_texts,padding=True,truncation=True)\n",
    "val_encodings =tokenizer(val_texts,padding=True,truncation=True)\n",
    "print(len(train_encodings['input_ids']),len(val_encodings['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21193 5299\n"
     ]
    }
   ],
   "source": [
    "train_tokens=list(map(lambda x: tokenizer.convert_ids_to_tokens(x),train_encodings['input_ids']))\n",
    "val_tokens=list(map(lambda x: tokenizer.convert_ids_to_tokens(x),val_encodings['input_ids']))\n",
    "print(len(train_tokens),len(val_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id={'O':0,'B-COM':1,'I-COM':2}\n",
    "id2tag={0:'O',1:'B-COM',2:'I-COM'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df['ProjectDescription'].to_list()\n",
    "tags=df['tags'].to_list()\n",
    "wds=df['words'].to_list()\n",
    "text_encodings=tokenizer(texts,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1284, 1132, 1702, 1106, 6030, 3675, 1114, 8724, 1113, 6356, 113, 1429, 120, 1479, 114, 1113, 1103, 8366, 2071, 131, 13134, 4733, 3582, 11954, 1826, 1111, 13673, 113, 3582, 15008, 117, 3850, 5715, 117, 3576, 119, 114, 1284, 787, 1231, 4717, 1106, 2936, 1106, 131, 16409, 17786, 1116, 1150, 1132, 4509, 1114, 1103, 2380, 1105, 1103, 2557, 2071, 113, 4268, 3644, 1954, 4570, 1104, 1292, 2557, 114, 119, 15397, 2646, 1658, 1766, 1643, 117, 5357, 3048, 2069, 2713, 117, 8790, 1874, 2069, 11381, 117, 18340, 15652, 1158, 4326, 117, 18340, 15652, 1158, 9868, 1658, 8954, 23806, 1116, 1150, 1138, 1215, 1103, 1826, 1104, 2967, 3582, 4031, 2557, 1105, 1169, 1660, 170, 7577, 1104, 1826, 120, 3672, 1111, 1147, 3026, 1104, 11482, 4203, 4989, 1103, 3675, 1132, 1113, 170, 1423, 118, 24255, 7616, 113, 178, 119, 174, 119, 26828, 1271, 1110, 1136, 23617, 1113, 1137, 1196, 1103, 1840, 114, 119, 2421, 1366, 1221, 1191, 1175, 1132, 1251, 3243, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(text_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26492\n"
     ]
    }
   ],
   "source": [
    "tkns1=[]\n",
    "for i in text_encodings['input_ids']:\n",
    "    tkns1.append(tokenizer.convert_ids_to_tokens(i))\n",
    "print(len(tkns1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: We are looking to schedule calls with experts on Monday (11/16) on the topic below: Companies offering background screening services for employers (background checks, drug tests, etc.) We’re hoping to speak to:Experts who are familiar with the industry and the companies below (please avoid current employees of these companies)IntelliCorp, GlobalHR Research, HireRight, Employment Screening Services, Employment Screening ResourcesCustomers who have used the services of multiple background check companies and can give a comparison of services / reasons for their choice of provider Please ensure the calls are on a single-blinded bases (i.e. Macquarie name is not disclosed on or before the call). Let us know if there are any questions. \n",
      "Companies: ['Employment Screening Resources', ' Employment Screening Services, Inc.', ' Global HR Research, LLC', ' HireRight, LLC', ' IntelliCorp Records Inc.']\n"
     ]
    }
   ],
   "source": [
    "x=df.loc[0,'ProjectDescription']\n",
    "y=df.loc[0,'Companies']\n",
    "print(\"Text:\",x)\n",
    "print(\"Companies:\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21193 5299\n"
     ]
    }
   ],
   "source": [
    "def encode_one_label(tg,xw,tokens):\n",
    "    labels = [tag2id[tag] for tag in tg] \n",
    "    assigned_labels,j=[-100 for j in range(len(tokens))],1\n",
    "    for i in range(len(xw)):\n",
    "        if j>=len(tokens):\n",
    "            break\n",
    "        if tokens[j][0]=='[' and tokens[j][-1]==']':\n",
    "            assigned_labels[j]=-100\n",
    "            j+=1\n",
    "        if j>=len(tokens):\n",
    "            break\n",
    "        if tokens[j]==xw[i]:\n",
    "            assigned_labels[j]=labels[i]\n",
    "            j+=1\n",
    "        elif tokens[j] in xw[i]:\n",
    "            ij,assigned_labels[j],joined_text=1,labels[i],tokens[j]\n",
    "            while j+ij < len(tokens):\n",
    "            \n",
    "                if tokens[j+ij][:2]=='##':\n",
    "                    joined_text=joined_text+tokens[j+ij][2:]\n",
    "                else:\n",
    "                    joined_text = joined_text+tokens[j+ij]\n",
    "                if joined_text==xw[i]:\n",
    "                    j=j+ij+1\n",
    "                    break\n",
    "                assigned_labels[j+ij]=-100\n",
    "                ij+=1\n",
    "\n",
    "    while j<len(tokens):\n",
    "        assigned_labels[j]=-100\n",
    "        j+=1\n",
    "    return assigned_labels\n",
    "\n",
    "def encode_labels(tgs,xws,tkn):\n",
    "    encoded_labels=[]\n",
    "    \n",
    "    for i in range(len(tkn)):\n",
    "        encoded_labels.append(encode_one_label(tgs[i],xws[i],tkn[i]))\n",
    "    return encoded_labels\n",
    "\n",
    "train_labels=encode_labels(train_tags,train_words,train_tokens)\n",
    "val_labels=encode_labels(val_tags,val_words,val_tokens)\n",
    "print(len(train_labels),len(val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CCDataset(train_encodings, train_labels)\n",
    "val_dataset = CCDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass,self).__init__()\n",
    "        self.l1=transformers.BertForTokenClassification.from_pretrained('bert-base-cased',num_labels=3)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768,512)\n",
    "        \n",
    "    def forward(inputs):\n",
    "        sequence_output, pooled_output = self.l1(inputs)\n",
    "        o2 = self.l2(sentence_output)\n",
    "        o3 = self.l3(o2)\n",
    "        \n",
    "        return o3\n",
    "model=BERTClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")\n",
    "labels = ['O','B-COM','I-COM']\n",
    "metric.compute(predictions=[labels],references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9a4e1c46b291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_list' is not defined"
     ]
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1683, in forward\n    return_dict=return_dict,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\n    return_dict=return_dict,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\n    output_attentions,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\n    output_attentions,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 290, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\nRuntimeError: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 11.17 GiB total capacity; 10.33 GiB already allocated; 84.44 MiB free; 10.70 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-4ee8921a21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1683, in forward\n    return_dict=return_dict,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\n    return_dict=return_dict,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\n    output_attentions,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\n    output_attentions,\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 290, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\nRuntimeError: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 11.17 GiB total capacity; 10.33 GiB already allocated; 84.44 MiB free; 10.70 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\"./ner-test\",learning_rate=LEARNING_RATE,\n",
    "                        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "                        per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "                        num_train_epochs=EPOCHS,\n",
    "                        weight_decay=0.01,\n",
    "                        warmup_steps=500,\n",
    "                        logging_dir='./logs',\n",
    "                        logging_steps=10,)\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79348"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 03:55:17.785602: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\n",
      "2021-02-10 03:55:17.785651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-14918a066d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboardX) (3.14.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboardX) (1.19.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboardX) (1.15.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
